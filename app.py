from flask import Flask, request, abort
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import *
import os
import traceback
import google.generativeai as genai
import threading
import requests
import time
from functools import lru_cache  # âœ… åŠ å…¥å¿«å–åŠŸèƒ½

# ğŸ”§ NEWï¼šQuickReply é¡åˆ¥
from linebot.models import QuickReply, QuickReplyButton, PostbackAction

# Flask è¨­å®š
app = Flask(__name__)

# LINE Bot Token & Secret
line_bot_api = LineBotApi(os.getenv('CHANNEL_ACCESS_TOKEN'))
handler = WebhookHandler(os.getenv('CHANNEL_SECRET'))

# Gemini API åˆå§‹åŒ–è¨­å®š
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

# âœ… GPT å›æ‡‰å‡½å¼ï¼ˆå¼·åŒ–æ¨¡å‹ + å¿«å– + éŒ¯èª¤è™•ç† + å®‰å…¨æ€§ï¼‰
@lru_cache(maxsize=256)
def GPT_response(text):
    try:
        model = genai.GenerativeModel("gemini-2.5-flash-lite")
        response = model.generate_content(
            text,
            generation_config={
                "temperature": 0.4,
                "max_output_tokens": 300,
                "top_p": 0.9,
                "top_k": 40
            },
            safety_settings=[
                {"category": "HARM_CATEGORY_SEXUAL", "threshold": 3},
                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": 3},
                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": 3},
                {"category": "HARM_CATEGORY_DANGEROUS", "threshold": 3}
            ]
        )
        answer = response.text.strip().replace("ã€‚", "")
        return answer
    except Exception as e:
        print("[Gemini ERROR]", e)
        return "âš ï¸ AI å›æ‡‰ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦æˆ–æª¢æŸ¥ API é‡‘é‘°ã€‚"

# æ¥æ”¶ LINE callback
@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers['X-Line-Signature']
    body = request.get_data(as_text=True)
    app.logger.info("Request body: " + body)

    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)

    return 'OK'

# åˆ†æ®µå·¥å…·ï¼ˆç”¨æ–¼ Flex Messageï¼‰
def split_text(text, max_length=400):
    return [text[i:i+max_length] for i in range(0, len(text), max_length)]

# è™•ç†ä½¿ç”¨è€…æ–‡å­—è¨Šæ¯ with Flex Message å›è¦†
@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    msg = event.message.text
    try:
        GPT_answer = GPT_response(msg)
        parts = split_text(GPT_answer, 400)

        bubbles = []
        for part in parts[:5]:
            bubble = {
                "type": "bubble",
                "body": {
                    "type": "box",
                    "layout": "vertical",
                    "contents": [{
                        "type": "text",
                        "text": part,
                        "wrap": True,
                        "size": "sm"
                    }]
                },
                "footer": {
                    "type": "box",
                    "layout": "horizontal",
                    "contents": [
                        {
                            # ğŸ”§ NEWï¼šFlex å…§éƒ¨æŒ‰éˆ•ï¼ˆåŸå¥ç¿»è­¯ï¼‰
                            "type": "button",
                            "style": "primary",
                            "color": "#1E88E5",
                            "action": {
                                "type": "postback",
                                "label": "ç¿»è­¯å°åŠ©ç†",
                                "data": f"translate_helper::{msg}"
                            }
                        }
                    ]
                }
            }
            bubbles.append(bubble)

        flex_contents = {
            "type": "carousel",
            "contents": bubbles
        }

        # ğŸ”§ NEWï¼šåº•éƒ¨ QuickReply å¸¸é§é¸å–®
        quick_reply = QuickReply(items=[
            QuickReplyButton(action=PostbackAction(label="ç¿»è­¯å°åŠ©ç†", data="launch_translate_helper"))
        ])

        response_list = [
            FlexSendMessage(alt_text="AI å›è¦†", contents=flex_contents),
            TextSendMessage(text="è«‹é¸æ“‡æ¥ä¸‹ä¾†çš„æ“ä½œï¼š", quick_reply=quick_reply)
        ]
        if len(parts) > 5:
            tips = TextSendMessage(text="âš ï¸ å›è¦†å…§å®¹è¼ƒé•·ï¼Œåƒ…é¡¯ç¤ºå‰äº”æ®µã€‚å¦‚éœ€å®Œæ•´å…§å®¹è«‹æ”¹ç”¨ Web æˆ–éƒµä»¶æŸ¥è©¢ã€‚")
            response_list.append(tips)

        line_bot_api.reply_message(event.reply_token, response_list)

    except:
        print(traceback.format_exc())
        line_bot_api.reply_message(event.reply_token, TextSendMessage('AI å›æ‡‰ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹æŸ¥çœ‹ä¼ºæœå™¨ Log è¨Šæ¯æˆ–ç¢ºèª API é‡‘é‘°æ˜¯å¦æœ‰æ•ˆ'))

# ğŸ”§ NEWï¼šç¿»è­¯å°åŠ©ç†å…¥å£èˆ‡ç¿»è­¯å›æ‡‰é‚è¼¯
@handler.add(PostbackEvent)
def handle_postback(event):
    data = event.postback.data

    if data == "launch_translate_helper":
        line_bot_api.reply_message(event.reply_token, TextSendMessage(
            text="ğŸ§  ç¿»è­¯å°åŠ©ç†å·²å•Ÿå‹•ï¼Œè«‹è¼¸å…¥ä½ æƒ³ç¿»è­¯æˆ–å„ªåŒ–çš„å¥å­ã€‚æˆ‘æœƒæä¾›æ­£å¼èªæ°£çš„ä¸­è‹±æ–‡å°ç…§ã€æ–‡æ³•å»ºè­°ã€åŒç¾©è©èˆ‡ä¾‹å¥ã€‚"
        ))
        return

    if data.startswith("translate_helper::"):
        text = data.split("::")[1]
        prompt = f"""ä½ ç¾åœ¨æ˜¯ä¸€å€‹æ­£å¼å°ˆæ¥­çš„ç¿»è­¯å°åŠ©ç†ï¼Œè«‹é‡å°ä»¥ä¸‹å…§å®¹é€²è¡Œèªè¨€å¢å¼·æœå‹™ã€‚
å›è¦†è«‹ä¾ç…§ä»¥ä¸‹æ ¼å¼ï¼š

ç¿»è­¯å°åŠ©ç†  
Chineseï¼š...(åŸæ–‡æˆ–ç¿»è­¯)  
Englishï¼š...(æ­£å¼èªæ°£ç¿»è­¯)  
æ–‡æ³•å»ºè­°ï¼š...  
åŒç¾©è©å»ºè­°ï¼š...  
å»¶ä¼¸ç”¨æ³• / ä¾‹å¥ï¼š...

ä»¥ä¸‹æ˜¯è¦ç¿»è­¯èˆ‡å„ªåŒ–çš„å…§å®¹ï¼š
{text}"""

        result = GPT_response(prompt)
        parts = split_text(result, 400)
        line_bot_api.reply_message(event.reply_token, [TextSendMessage(text=p) for p in parts])

# æ–°æˆå“¡åŠ å…¥ç¾¤çµ„æ­¡è¿è¨Šæ¯
@handler.add(MemberJoinedEvent)
def welcome(event):
    uid = event.joined.members[0].user_id
    gid = event.source.group_id
    profile = line_bot_api.get_group_member_profile(gid, uid)
    name = profile.display_name
    message = TextSendMessage(text=f'{name} æ­¡è¿åŠ å…¥ï¼ç›®å‰æˆ‘æ­£åœ¨ç™½é‡‘æ‰“å·¥ï¼è«‹å¤šå¤šæŒ‡æ•™ï¼')
    line_bot_api.reply_message(event.reply_token, message)

# Render è‡ªæˆ‘å–šé†’æ©Ÿåˆ¶ï¼ˆé¿å…ç¡æ­»ï¼‰
WAKE_URL = 'https://linebot-openai-kysy.onrender.com/callback'  # â¬…ï¸ æ”¹æˆä½ çš„æ­£å¼ç¶²å€

def keep_awake():
    while True:
        try:
            res = requests.get(WAKE_URL)
            print(f"[WAKE-UP] Status: {res.status_code}")
        except Exception as e:
            print(f"[WAKE-UP ERROR] {e}")
        time.sleep(840)  # æ¯ 14 åˆ†é˜å–šé†’ä¸€æ¬¡

# å•Ÿå‹•ä¼ºæœå™¨
if __name__ == "__main__":
    threading.Thread(target=keep_awake, daemon=True).start()
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port)
